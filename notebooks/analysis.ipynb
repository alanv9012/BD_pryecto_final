{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Mobility Pattern Analysis\n",
    "\n",
    "## Project: Analysis of Urban Mobility Patterns using Apache Spark\n",
    "\n",
    "This notebook implements a complete data analysis pipeline for understanding urban mobility patterns from taxi trip data.\n",
    "\n",
    "### Objectives:\n",
    "- Apply Apache Spark for processing and analyzing urban mobility data\n",
    "- Identify mobility patterns (peak hours, busiest zones, average trip duration, etc.)\n",
    "- Develop a complete data analysis workflow: ingestion, cleaning, transformation, analysis, and visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Java compatibility options configured for Java 17+\n"
     ]
    }
   ],
   "source": [
    "# Fix for Java 17+ compatibility - MUST be set before importing PySpark\n",
    "# These options allow Spark to work with newer Java versions\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set Java options BEFORE importing PySpark\n",
    "java_opts = [\n",
    "    '--add-opens=java.base/java.lang=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.io=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.net=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.nio=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.util=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/sun.security.action=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED',\n",
    "    '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED',\n",
    "    '--add-opens=java.base/javax.security.auth=ALL-UNNAMED',\n",
    "    '--enable-native-access=ALL-UNNAMED',\n",
    "    '-Dio.netty.tryReflectionSetAccessible=true',\n",
    "    '-Dhadoop.security.authentication=simple',\n",
    "    '-Dhadoop.security.authorization=false'\n",
    "]\n",
    "\n",
    "# Set environment variables before PySpark is imported\n",
    "os.environ['JAVA_OPTS'] = ' '.join(java_opts)\n",
    "os.environ['_JAVA_OPTIONS'] = ' '.join(java_opts)\n",
    "\n",
    "# Add src directory to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import project modules (PySpark is imported here via src modules)\n",
    "from src.config import *\n",
    "from src.data_processing import *\n",
    "from src.zone_mapping import *\n",
    "from src.analysis import *\n",
    "from src.mongodb_operations import *\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(\"Java compatibility options configured for Java 17+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Please update MongoDB URI before saving to MongoDB\n"
     ]
    }
   ],
   "source": [
    "# MongoDB Configuration\n",
    "# TODO: Replace with your MongoDB Atlas connection string\n",
    "# Format: mongodb+srv://username:password@cluster.mongodb.net/\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\", \"mongodb+srv://a271455_db_user:I3Sxtk54C3J5moXw@bigdatacluster.zagwkmh.mongodb.net/?appName=BigDataCluster\")\n",
    "\n",
    "# Update config if needed\n",
    "if MONGODB_URI != \"mongodb+srv://a271455_db_user:I3Sxtk54C3J5moXw@bigdatacluster.zagwkmh.mongodb.net/?appName=BigDataCluster\":\n",
    "    from src import config\n",
    "    config.MONGODB_URI = MONGODB_URI\n",
    "    print(\"MongoDB URI configured\")\n",
    "else:\n",
    "    print(\"WARNING: Please update MongoDB URI before saving to MongoDB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:21:08,719 - src.data_processing - INFO - Spark session created successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 4.0.1\n",
      "Spark Master: local[*]\n",
      "Spark session initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create Spark session\n",
    "spark = create_spark_session()\n",
    "\n",
    "# Display Spark version and configuration\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark Master: {spark.sparkContext.master}\")\n",
    "print(\"Spark session initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Ingestion and Initial Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:21:08,726 - src.data_processing - INFO - Loading taxi data from C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\n",
      "2025-11-27 09:21:08,727 - src.data_processing - INFO - Found 10 parquet files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:21:12,599 - src.data_processing - INFO - Loaded 40236152 total records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Schema ===\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load taxi data\n",
    "taxi_data_path = str(TAXI_DATA_DIR)\n",
    "print(f\"Loading data from: {taxi_data_path}\")\n",
    "\n",
    "df_raw = load_taxi_data(spark, taxi_data_path)\n",
    "\n",
    "# Display schema\n",
    "print(\"\\n=== Data Schema ===\")\n",
    "df_raw.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 40,236,152\n",
      "Total columns: 20\n",
      "\n",
      "Column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee', 'cbd_congestion_fee']\n",
      "\n",
      "=== Sample Data (first 5 rows) ===\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|1       |2025-03-01 00:17:16 |2025-03-01 00:25:52  |1              |0.9          |1         |N                 |140         |236         |1           |7.9        |3.5  |0.5    |2.6       |0.0         |1.0                  |15.5        |2.5                 |0.0        |0.0               |\n",
      "|1       |2025-03-01 00:37:38 |2025-03-01 00:43:51  |1              |0.6          |1         |N                 |140         |262         |1           |6.5        |3.5  |0.5    |2.3       |0.0         |1.0                  |13.8        |2.5                 |0.0        |0.0               |\n",
      "|2       |2025-03-01 00:24:35 |2025-03-01 00:39:49  |1              |1.94         |1         |N                 |161         |68          |1           |14.9       |1.0  |0.5    |5.16      |0.0         |1.0                  |25.81       |2.5                 |0.0        |0.75              |\n",
      "|2       |2025-03-01 00:56:16 |2025-03-01 01:01:35  |2              |0.95         |1         |N                 |231         |13          |1           |7.2        |1.0  |0.5    |2.59      |0.0         |1.0                  |15.54       |2.5                 |0.0        |0.75              |\n",
      "|1       |2025-03-01 00:01:44 |2025-03-01 00:10:00  |1              |1.5          |1         |N                 |163         |236         |1           |8.6        |4.25 |0.5    |2.85      |0.0         |1.0                  |17.2        |2.5                 |0.0        |0.75              |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics\n",
    "print(f\"Total records: {df_raw.count():,}\")\n",
    "print(f\"Total columns: {len(df_raw.columns)}\")\n",
    "print(f\"\\nColumn names: {df_raw.columns}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\n=== Sample Data (first 5 rows) ===\")\n",
    "df_raw.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Null Value Analysis ===\n",
      "-RECORD 0--------------------\n",
      " VendorID              | 0   \n",
      " tpep_pickup_datetime  | 0   \n",
      " tpep_dropoff_datetime | 0   \n",
      " passenger_count       | 0   \n",
      " trip_distance         | 0   \n",
      " RatecodeID            | 0   \n",
      " store_and_fwd_flag    | 0   \n",
      " PULocationID          | 0   \n",
      " DOLocationID          | 0   \n",
      " payment_type          | 0   \n",
      " fare_amount           | 0   \n",
      " extra                 | 0   \n",
      " mta_tax               | 0   \n",
      " tip_amount            | 0   \n",
      " tolls_amount          | 0   \n",
      " improvement_surcharge | 0   \n",
      " total_amount          | 0   \n",
      " congestion_surcharge  | 0   \n",
      " Airport_fee           | 0   \n",
      " cbd_congestion_fee    | 0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in key columns\n",
    "from pyspark.sql.functions import col, isnan, isnull, when, count\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "print(\"=== Null Value Analysis ===\")\n",
    "\n",
    "# Get column types to determine which columns can use isnan()\n",
    "schema = df_raw.schema\n",
    "column_types = {field.name: field.dataType for field in schema.fields}\n",
    "\n",
    "# Build null count expressions - only use isnan() for numeric types\n",
    "null_expressions = []\n",
    "for col_name in df_raw.columns:\n",
    "    col_type = column_types.get(col_name)\n",
    "    # For numeric types, check both isnull and isnan\n",
    "    if isinstance(col_type, NumericType):\n",
    "        null_expressions.append(count(when(isnull(col(col_name)) | isnan(col(col_name)), col(col_name))).alias(col_name))\n",
    "    else:\n",
    "        # For non-numeric types (timestamps, strings), only check isnull\n",
    "        null_expressions.append(count(when(isnull(col(col_name)), col(col_name))).alias(col_name))\n",
    "\n",
    "null_counts = df_raw.select(null_expressions)\n",
    "null_counts.show(vertical=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:21:18,729 - src.data_processing - INFO - Starting complete preprocessing pipeline\n",
      "2025-11-27 09:21:18,730 - src.data_processing - INFO - Loading taxi data from C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\n",
      "2025-11-27 09:21:18,731 - src.data_processing - INFO - Found 10 parquet files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:21:19,094 - src.data_processing - INFO - Loaded 40236152 total records\n",
      "2025-11-27 09:21:19,094 - src.data_processing - INFO - Standardizing column names\n",
      "2025-11-27 09:21:19,128 - src.data_processing - INFO - Starting data cleaning process\n",
      "2025-11-27 09:21:19,941 - src.data_processing - INFO - After filtering nulls in pickup_datetime: 40236152 -> 40236152 records\n",
      "2025-11-27 09:21:20,983 - src.data_processing - INFO - After filtering nulls in dropoff_datetime: 40236152 -> 40236152 records\n",
      "2025-11-27 09:21:22,185 - src.data_processing - INFO - After filtering nulls in trip_distance_km: 40236152 -> 40236152 records\n",
      "2025-11-27 09:21:23,628 - src.data_processing - INFO - After filtering NaN in trip_distance_km: 40236152 -> 40236152 records\n",
      "2025-11-27 09:21:25,056 - src.data_processing - INFO - After filtering nulls in fare_amount: 40236152 -> 40236152 records\n",
      "2025-11-27 09:21:26,569 - src.data_processing - INFO - After filtering NaN in fare_amount: 40236152 -> 40236152 records\n",
      "2025-11-27 09:21:41,761 - src.data_processing - INFO - After removing duplicates: 40236152 -> 39480582 records\n",
      "2025-11-27 09:21:53,978 - src.data_processing - INFO - Cleaned data: 40236152 -> 39480582 records (755570 removed)\n",
      "2025-11-27 09:21:53,979 - src.data_processing - INFO - Adding derived columns\n",
      "2025-11-27 09:21:54,179 - src.data_processing - INFO - Filtering outliers\n",
      "2025-11-27 09:22:43,210 - src.data_processing - INFO - Outlier filtering: 38668502 -> 35549533 records (3118969 removed)\n",
      "2025-11-27 09:23:09,213 - src.data_processing - INFO - Preprocessing complete. Final record count: 35549533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing complete!\n",
      "Final record count: 35,549,533\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names and clean data\n",
    "print(\"Starting data preprocessing...\")\n",
    "\n",
    "df_cleaned = preprocess_taxi_data(spark, taxi_data_path)\n",
    "\n",
    "print(f\"\\nPreprocessing complete!\")\n",
    "print(f\"Final record count: {df_cleaned.count():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cleaned Data Schema ===\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance_km: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      " |-- trip_duration_min: double (nullable = true)\n",
      " |-- hour_of_day: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- day_name: string (nullable = false)\n",
      "\n",
      "\n",
      "=== Sample Cleaned Data ===\n",
      "+-------------------+-------------------+-----------------+-----------+-----------+--------+----------------+-----------+---------------+\n",
      "|pickup_datetime    |dropoff_datetime   |trip_duration_min|hour_of_day|day_of_week|day_name|trip_distance_km|fare_amount|passenger_count|\n",
      "+-------------------+-------------------+-----------------+-----------+-----------+--------+----------------+-----------+---------------+\n",
      "|2025-02-28 18:06:48|2025-02-28 18:18:44|11.93            |18         |6          |Friday  |1.43            |12.1       |1              |\n",
      "|2025-02-28 18:26:24|2025-02-28 18:34:48|8.4              |18         |6          |Friday  |1.6             |10.7       |1              |\n",
      "|2025-02-28 18:18:24|2025-02-28 18:31:42|13.3             |18         |6          |Friday  |2.7             |14.9       |3              |\n",
      "|2025-02-28 18:21:04|2025-02-28 18:35:24|14.33            |18         |6          |Friday  |2.2             |14.2       |1              |\n",
      "|2025-02-28 18:53:35|2025-02-28 19:07:00|13.42            |18         |6          |Friday  |3.19            |16.3       |1              |\n",
      "|2025-02-28 18:08:25|2025-02-28 18:23:19|14.9             |18         |6          |Friday  |2.8             |14.9       |1              |\n",
      "|2025-02-28 18:47:35|2025-02-28 19:00:13|12.63            |18         |6          |Friday  |2.0             |12.8       |2              |\n",
      "|2025-02-28 18:05:33|2025-02-28 18:23:42|18.15            |18         |6          |Friday  |7.26            |30.3       |1              |\n",
      "|2025-02-28 18:58:22|2025-02-28 19:22:02|23.67            |18         |6          |Friday  |5.4             |24.7       |1              |\n",
      "|2025-02-28 18:41:31|2025-02-28 18:55:32|14.02            |18         |6          |Friday  |2.84            |16.3       |2              |\n",
      "+-------------------+-------------------+-----------------+-----------+-----------+--------+----------------+-----------+---------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Display cleaned data schema\n",
    "print(\"=== Cleaned Data Schema ===\")\n",
    "df_cleaned.printSchema()\n",
    "\n",
    "# Show sample of cleaned data\n",
    "print(\"\\n=== Sample Cleaned Data ===\")\n",
    "df_cleaned.select(\n",
    "    \"pickup_datetime\", \"dropoff_datetime\", \"trip_duration_min\",\n",
    "    \"hour_of_day\", \"day_of_week\", \"day_name\",\n",
    "    \"trip_distance_km\", \"fare_amount\", \"passenger_count\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Enrichment - Zone Assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:23:53,727 - src.zone_mapping - INFO - Loading NYC taxi zone lookup from C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\\taxi_zone_lookup.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading official NYC zone lookup from: C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\\taxi_zone_lookup.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:23:54,149 - src.zone_mapping - INFO - Loaded 265 zone lookups\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 265 official NYC zones\n",
      "+-----------+-------------+-----------------------+------------+\n",
      "|location_id|borough      |zone_name              |service_zone|\n",
      "+-----------+-------------+-----------------------+------------+\n",
      "|1          |EWR          |Newark Airport         |EWR         |\n",
      "|2          |Queens       |Jamaica Bay            |Boro Zone   |\n",
      "|3          |Bronx        |Allerton/Pelham Gardens|Boro Zone   |\n",
      "|4          |Manhattan    |Alphabet City          |Yellow Zone |\n",
      "|5          |Staten Island|Arden Heights          |Boro Zone   |\n",
      "|6          |Staten Island|Arrochar/Fort Wadsworth|Boro Zone   |\n",
      "|7          |Queens       |Astoria                |Boro Zone   |\n",
      "|8          |Queens       |Astoria Park           |Boro Zone   |\n",
      "|9          |Queens       |Auburndale             |Boro Zone   |\n",
      "|10         |Queens       |Baisley Park           |Boro Zone   |\n",
      "+-----------+-------------+-----------------------+------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Try to use official NYC zone lookup table first\n",
    "from src.config import ZONES_LOOKUP_PATH\n",
    "zones_df = None\n",
    "\n",
    "if ZONES_LOOKUP_PATH.exists():\n",
    "    print(f\"Loading official NYC zone lookup from: {ZONES_LOOKUP_PATH}\")\n",
    "    try:\n",
    "        from src.zone_mapping import load_nyc_zone_lookup\n",
    "        zones_df = load_nyc_zone_lookup(spark, str(ZONES_LOOKUP_PATH))\n",
    "        print(f\"✓ Loaded {zones_df.count()} official NYC zones\")\n",
    "        zones_df.show(10, truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading official zone lookup: {e}\")\n",
    "        zones_df = None\n",
    "\n",
    "# Fallback to custom zones if lookup table not available\n",
    "if zones_df is None:\n",
    "    zones_path = str(ZONES_DATA_PATH)\n",
    "    print(f\"Loading custom zones from: {zones_path}\")\n",
    "    try:\n",
    "        zones_df = load_zones(spark, zones_path)\n",
    "        print(f\"✓ Loaded {zones_df.count()} custom zones\")\n",
    "        zones_df.show(truncate=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading zones file: {e}\")\n",
    "        print(\"Creating zones from data...\")\n",
    "        zones_df = create_zones_from_data(df_cleaned, num_zones=20)\n",
    "        zones_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:23:54,294 - src.zone_mapping - INFO - Enriching trips with zone information\n",
      "2025-11-27 09:23:54,303 - src.zone_mapping - INFO - Loading NYC taxi zone lookup from C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\\taxi_zone_lookup.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching trips with zone information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:23:54,489 - src.zone_mapping - INFO - Loaded 265 zone lookups\n",
      "2025-11-27 09:23:54,560 - src.zone_mapping - INFO - Using official NYC zone lookup table for pickup zones\n",
      "2025-11-27 09:23:54,562 - src.zone_mapping - INFO - Loading NYC taxi zone lookup from C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\Taxi Dataset\\taxi_zone_lookup.csv\n",
      "2025-11-27 09:23:54,760 - src.zone_mapping - INFO - Loaded 265 zone lookups\n",
      "2025-11-27 09:23:54,803 - src.zone_mapping - INFO - Using official NYC zone lookup table for dropoff zones\n",
      "2025-11-27 09:23:54,804 - src.zone_mapping - INFO - Zone enrichment complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone enrichment complete!\n",
      "Records with pickup zone: 35,549,393\n",
      "Records with dropoff zone: 35,549,312\n"
     ]
    }
   ],
   "source": [
    "# Enrich trips with zone information\n",
    "print(\"Enriching trips with zone information...\")\n",
    "\n",
    "df_enriched = enrich_with_zones(df_cleaned, zones_df)\n",
    "\n",
    "print(\"Zone enrichment complete!\")\n",
    "print(f\"Records with pickup zone: {df_enriched.filter(col('pickup_zone_name').isNotNull()).count():,}\")\n",
    "print(f\"Records with dropoff zone: {df_enriched.filter(col('dropoff_zone_name').isNotNull()).count():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Enriched Data ===\n",
      "+-------------------+-----------+--------+----------------------------+------------------------------+-----------------+----------------+-----------+\n",
      "|pickup_datetime    |hour_of_day|day_name|pickup_zone_name            |dropoff_zone_name             |trip_duration_min|trip_distance_km|fare_amount|\n",
      "+-------------------+-----------+--------+----------------------------+------------------------------+-----------------+----------------+-----------+\n",
      "|2025-02-28 18:06:48|18         |Friday  |Penn Station/Madison Sq West|Gramercy                      |11.93            |1.43            |12.1       |\n",
      "|2025-02-28 18:26:24|18         |Friday  |TriBeCa/Civic Center        |Flatiron                      |8.4              |1.6             |10.7       |\n",
      "|2025-02-28 18:18:24|18         |Friday  |Lenox Hill West             |Gramercy                      |13.3             |2.7             |14.9       |\n",
      "|2025-02-28 18:21:04|18         |Friday  |West Village                |Clinton East                  |14.33            |2.2             |14.2       |\n",
      "|2025-02-28 18:53:35|18         |Friday  |Flatiron                    |Lincoln Square East           |13.42            |3.19            |16.3       |\n",
      "|2025-02-28 18:08:25|18         |Friday  |TriBeCa/Civic Center        |Murray Hill                   |14.9             |2.8             |14.9       |\n",
      "|2025-02-28 18:47:35|18         |Friday  |Clinton East                |Lenox Hill West               |12.63            |2.0             |12.8       |\n",
      "|2025-02-28 18:05:33|18         |Friday  |LaGuardia Airport           |Long Island City/Hunters Point|18.15            |7.26            |30.3       |\n",
      "|2025-02-28 18:58:22|18         |Friday  |Lower East Side             |East Harlem South             |23.67            |5.4             |24.7       |\n",
      "|2025-02-28 18:41:31|18         |Friday  |Morningside Heights         |Lincoln Square East           |14.02            |2.84            |16.3       |\n",
      "+-------------------+-----------+--------+----------------------------+------------------------------+-----------------+----------------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Show sample of enriched data\n",
    "print(\"=== Sample Enriched Data ===\")\n",
    "df_enriched.select(\n",
    "    \"pickup_datetime\", \"hour_of_day\", \"day_name\",\n",
    "    \"pickup_zone_name\", \"dropoff_zone_name\",\n",
    "    \"trip_duration_min\", \"trip_distance_km\", \"fare_amount\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis\n",
    "\n",
    "### 6.1 Demand by Hour of Day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:25:12,763 - src.analysis - INFO - Analyzing demand by hour of day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hourly Demand Analysis ===\n",
      "+-----------+-----------+------------------+------------------+--------------------+------------------+\n",
      "|hour_of_day|total_trips|avg_duration_min  |avg_distance_km   |total_revenue       |avg_fare_amount   |\n",
      "+-----------+-----------+------------------+------------------+--------------------+------------------+\n",
      "|0          |553720     |17.16531934912954 |4.930820504948354 |1.2248065770000007E7|22.119601549519626|\n",
      "|1          |1034863    |16.970264421474166|3.899055884691975 |2.0602458800000027E7|19.908392511859084|\n",
      "|2          |1410708    |16.90064107526149 |3.342605649078331 |2.691769613999994E7 |19.08098354868615 |\n",
      "|3          |1505194    |16.745674756875218|3.200455828285262 |2.8238022710000128E7|18.760387504866568|\n",
      "|4          |1566734    |17.04573685130978 |3.1949266499609914|2.9628903550000057E7|18.911253314219298|\n",
      "|5          |1674953    |17.56829912242315 |3.184215628737046 |3.2179147750000056E7|19.211970574696757|\n",
      "|6          |1823951    |17.869632572366253|3.2575934331569174|3.568779767000002E7 |19.566204174344605|\n",
      "|7          |1908859    |18.246682086000106|3.3490697112777834|3.819005589999995E7 |20.006745338445608|\n",
      "|8          |2047076    |19.465024410427326|3.5475974072286456|4.284077318000028E7 |20.927788308787893|\n",
      "|9          |2116297    |19.797213864594557|3.4675248370148295|4.425602860000034E7 |20.91201216086416 |\n",
      "|10         |2060773    |19.536330323621282|3.519321895230576 |4.284388018000031E7 |20.790198716695294|\n",
      "|11         |2284474    |18.17738078437311 |3.2319232698643083|4.473958684000033E7 |19.584196116918086|\n",
      "|12         |2384927    |16.343334315893095|3.038802416174586 |4.381786451000031E7 |18.3728325898446  |\n",
      "|13         |2153307    |15.66978235337553 |3.2096689882120866|3.9974977010000415E7|18.564457836249275|\n",
      "|14         |2103055    |15.336973051108988|3.4564221620452193|3.959861906000038E7 |18.829093418859888|\n",
      "|15         |2157599    |15.200128499317964|3.5018199721078895|4.086932317000054E7 |18.942038427900894|\n",
      "|16         |2018248    |15.627903176418345|3.699884350188883 |3.9904932280000366E7|19.772065811535732|\n",
      "|17         |1573648    |15.665901313381395|4.038764081929376 |3.2548517420000225E7|20.683480308175795|\n",
      "|18         |1110429    |14.925044446785869|4.090191772729276 |2.282131960999995E7 |20.551804401722173|\n",
      "|19         |729201     |13.878884971359044|3.756907190198588 |1.3856527030000001E7|19.00234233085254 |\n",
      "|20         |481024     |13.143999571746923|3.5659059631120216|8612697.140000006   |17.904921875000014|\n",
      "|21         |325275     |13.315423626162477|3.895227453693029 |6047027.37          |18.59050763200369 |\n",
      "|22         |252449     |15.030687940930655|5.094024179141135 |5790002.4500000095  |22.935335255833888|\n",
      "|23         |272583     |17.095765033035804|5.980926653533056 |6968342.480000001   |25.56411250885052 |\n",
      "+-----------+-----------+------------------+------------------+--------------------+------------------+\n",
      "\n",
      "\n",
      "Peak hour: 12:00 with 2,384,933 trips\n"
     ]
    }
   ],
   "source": [
    "# Analyze demand by hour\n",
    "hourly_demand = analyze_demand_by_hour(df_enriched)\n",
    "\n",
    "if hourly_demand:\n",
    "    print(\"=== Hourly Demand Analysis ===\")\n",
    "    hourly_demand.show(24, truncate=False)\n",
    "    \n",
    "    # Find peak hours\n",
    "    from pyspark.sql.functions import desc\n",
    "    peak_hour = hourly_demand.orderBy(desc(\"total_trips\")).first()\n",
    "    print(f\"\\nPeak hour: {peak_hour['hour_of_day']}:00 with {peak_hour['total_trips']:,} trips\")\n",
    "else:\n",
    "    print(\"Hourly analysis not available (missing hour_of_day column)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Demand by Day of Week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:26:10,292 - src.analysis - INFO - Analyzing demand by day of week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Daily Demand Analysis ===\n",
      "+-----------+---------+-----------+------------------+------------------+--------------------+------------------+----------+\n",
      "|day_of_week|day_name |total_trips|avg_duration_min  |avg_distance_km   |total_revenue       |avg_fare_amount   |is_weekend|\n",
      "+-----------+---------+-----------+------------------+------------------+--------------------+------------------+----------+\n",
      "|1          |Sunday   |3949165    |16.494513040098347|4.177484131455638 |8.444736715999912E7 |21.383600624435577|Weekend   |\n",
      "|2          |Monday   |4204426    |16.96077803248292 |3.7576852202892885|8.468803271999939E7 |20.142590860202887|Weekday   |\n",
      "|3          |Tuesday  |4950167    |17.013899821965648|3.338673242741097 |9.507891916999906E7 |19.20721445761306 |Weekday   |\n",
      "|4          |Wednesday|5378527    |17.30239693879018 |3.295462919494521 |1.0406386495999856E8|19.348023159500467|Weekday   |\n",
      "|5          |Thursday |5691531    |17.76377707685337 |3.3719379372615137|1.1250968948999898E8|19.76791297280099 |Weekday   |\n",
      "|6          |Friday   |5764053    |17.069051387973097|3.388481167678377 |1.1125302349999884E8|19.30117982953988 |Weekday   |\n",
      "|7          |Saturday |5611468    |15.992441521541261|3.372188288340943 |1.071413592499994E8 |19.093285259757234|Weekend   |\n",
      "+-----------+---------+-----------+------------------+------------------+--------------------+------------------+----------+\n",
      "\n",
      "\n",
      "=== Weekday vs Weekend Comparison ===\n",
      "+----------+-----------+--------------------+\n",
      "|is_weekend|total_trips|total_revenue       |\n",
      "+----------+-----------+--------------------+\n",
      "|Weekday   |25988777   |5.075944975899947E8 |\n",
      "|Weekend   |9560635    |1.9158873284999853E8|\n",
      "+----------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze demand by day of week\n",
    "daily_demand = analyze_demand_by_day(df_enriched)\n",
    "\n",
    "if daily_demand:\n",
    "    print(\"=== Daily Demand Analysis ===\")\n",
    "    daily_demand.show(truncate=False)\n",
    "    \n",
    "    # Compare weekdays vs weekends\n",
    "    from pyspark.sql.functions import sum as spark_sum\n",
    "    weekday_weekend = daily_demand.groupBy(\"is_weekend\").agg(\n",
    "        spark_sum(\"total_trips\").alias(\"total_trips\"),\n",
    "        spark_sum(\"total_revenue\").alias(\"total_revenue\")\n",
    "    )\n",
    "    print(\"\\n=== Weekday vs Weekend Comparison ===\")\n",
    "    weekday_weekend.show(truncate=False)\n",
    "else:\n",
    "    print(\"Daily analysis not available (missing day_of_week column)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Zone Activity Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:27:08,142 - src.analysis - INFO - Analyzing zone activity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 10 Origin Zones ===\n",
      "+--------------+----------------------------+------------------+--------------------+------------------+\n",
      "|pickup_zone_id|pickup_zone_name            |total_trips_origin|total_revenue_origin|avg_fare_origin   |\n",
      "+--------------+----------------------------+------------------+--------------------+------------------+\n",
      "|237           |Upper East Side South       |1600394           |2.1118982120000035E7|13.196114281858113|\n",
      "|161           |Midtown Center              |1583605           |2.6024056060000014E7|16.43342630264492 |\n",
      "|132           |JFK Airport                 |1451286           |9.322422401999903E7 |64.23559795932644 |\n",
      "|236           |Upper East Side North       |1401977           |1.930583591000004E7 |13.770436968652154|\n",
      "|186           |Penn Station/Madison Sq West|1162751           |1.9544266700000018E7|16.80864320907917 |\n",
      "|162           |Midtown East                |1142651           |1.8107670780000012E7|15.847070347813998|\n",
      "|230           |Times Sq/Theatre District   |1125331           |2.1364864219999988E7|18.985404489878967|\n",
      "|142           |Lincoln Square East         |1026925           |1.48968945E7        |14.506312048104778|\n",
      "|138           |LaGuardia Airport           |981249            |4.357832014000001E7 |44.41107215395889 |\n",
      "|170           |Murray Hill                 |966482            |1.518054723999999E7 |15.707014967686922|\n",
      "+--------------+----------------------------+------------------+--------------------+------------------+\n",
      "\n",
      "\n",
      "=== Top 10 Destination Zones ===\n",
      "+---------------+-------------------------+-----------------------+-------------------------+--------------------+\n",
      "|dropoff_zone_id|dropoff_zone_name        |total_trips_destination|total_revenue_destination|avg_fare_destination|\n",
      "+---------------+-------------------------+-----------------------+-------------------------+--------------------+\n",
      "|236            |Upper East Side North    |1470683                |2.0777375670000054E7     |14.127705066285566  |\n",
      "|237            |Upper East Side South    |1444317                |1.9293521950000033E7     |13.358232264800616  |\n",
      "|161            |Midtown Center           |1284218                |2.0763126279999975E7     |16.167914076893467  |\n",
      "|230            |Times Sq/Theatre District|1047501                |2.177526262000003E7      |20.787820364849324  |\n",
      "|170            |Murray Hill              |1006069                |1.5784572959999975E7     |15.689354268941766  |\n",
      "|162            |Midtown East             |958726                 |1.525444941E7            |15.911166913174359  |\n",
      "|68             |East Chelsea             |912253                 |1.5064880580000008E7     |16.513928241397952  |\n",
      "|142            |Lincoln Square East      |910104                 |1.3787307789999973E7     |15.149156349164462  |\n",
      "|239            |Upper West Side South    |908884                 |1.4430941299999943E7     |15.877649182953977  |\n",
      "|141            |Lenox Hill West          |868089                 |1.2808983029999914E7     |14.755379955280983  |\n",
      "+---------------+-------------------------+-----------------------+-------------------------+--------------------+\n",
      "\n",
      "\n",
      "=== Top 20 Zones by Total Activity ===\n",
      "+-------+----------------------------+--------------+--------------------+------------------+\n",
      "|zone_id|zone_name                   |total_activity|total_revenue       |avg_fare          |\n",
      "+-------+----------------------------+--------------+--------------------+------------------+\n",
      "|237    |Upper East Side South       |3044714       |4.041252168000006E7 |13.273010758974426|\n",
      "|236    |Upper East Side North       |2872661       |4.0083235650000095E7|13.953346966453784|\n",
      "|161    |Midtown Center              |2867817       |4.6787083699999996E7|16.314529030269362|\n",
      "|230    |Times Sq/Theatre District   |2172831       |4.3140115210000016E7|19.85433529344897 |\n",
      "|162    |Midtown East                |2101375       |3.336206803000001E7 |15.876303862946884|\n",
      "|170    |Murray Hill                 |1972549       |3.0965096729999967E7|15.698011420755565|\n",
      "|142    |Lincoln Square East         |1937028       |2.8684179889999975E7|14.808345511784019|\n",
      "|186    |Penn Station/Madison Sq West|1929236       |3.1571663790000018E7|16.364853128388656|\n",
      "|68     |East Chelsea                |1841713       |3.1171413439999998E7|16.92522854538139 |\n",
      "|234    |Union Sq                    |1825975       |2.7059765380000025E7|14.819351513574953|\n",
      "|239    |Upper West Side South       |1803600       |2.7482117229999866E7|15.237368169217048|\n",
      "|163    |Midtown North               |1764028       |2.9560664410000034E7|16.757480272421997|\n",
      "|132    |JFK Airport                 |1741038       |1.1267667913999893E8|64.71810445263051 |\n",
      "|48     |Clinton East                |1664392       |2.8284767869999945E7|16.99405420718193 |\n",
      "|79     |East Village                |1660622       |2.6665275499999993E7|16.057402286613083|\n",
      "|141    |Lenox Hill West             |1629983       |2.3279137589999832E7|14.28182845465249 |\n",
      "|164    |Midtown South               |1494844       |2.5641670670000006E7|17.153409098206907|\n",
      "|249    |West Village                |1430699       |2.1645285149999972E7|15.129167735491514|\n",
      "|140    |Lenox Hill East             |1368178       |2.1715687939999964E7|15.871975678603196|\n",
      "|246    |West Chelsea/Hudson Yards   |1356531       |2.193429248999999E7 |16.16940010217237 |\n",
      "+-------+----------------------------+--------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze zone activity\n",
    "zone_results = analyze_zone_activity(df_enriched)\n",
    "\n",
    "if zone_results.get(\"top_origin_zones\"):\n",
    "    print(\"=== Top 10 Origin Zones ===\")\n",
    "    zone_results[\"top_origin_zones\"].show(truncate=False)\n",
    "\n",
    "if zone_results.get(\"top_destination_zones\"):\n",
    "    print(\"\\n=== Top 10 Destination Zones ===\")\n",
    "    zone_results[\"top_destination_zones\"].show(truncate=False)\n",
    "\n",
    "if zone_results.get(\"combined_zone_activity\"):\n",
    "    print(\"\\n=== Top 20 Zones by Total Activity ===\")\n",
    "    zone_results[\"combined_zone_activity\"].show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Trip Duration and Distance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:28:52,593 - src.analysis - INFO - Analyzing trip duration and distance patterns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Duration and Distance Statistics (by_hour) ===\n",
      "+-----------+------------------+----------------+----------------+------------------+---------------+---------------+\n",
      "|hour_of_day|avg_duration_min  |min_duration_min|max_duration_min|avg_distance_km   |min_distance_km|max_distance_km|\n",
      "+-----------+------------------+----------------+----------------+------------------+---------------+---------------+\n",
      "|0          |17.165329436049706|1.0             |179.4           |4.930826628669059 |0.1            |183.4          |\n",
      "|1          |16.970264421474166|1.0             |176.77          |3.899050695599312 |0.1            |188.7          |\n",
      "|2          |16.90064107526149 |1.0             |179.0           |3.342605975155733 |0.1            |196.3          |\n",
      "|3          |16.745674756875218|1.0             |179.48          |3.200449038462821 |0.1            |160.84         |\n",
      "|4          |17.045731122365922|1.0             |178.83          |3.194923857576415 |0.1            |198.0          |\n",
      "|5          |17.568303965362645|1.0             |180.0           |3.1842212562255447|0.1            |181.9          |\n",
      "|6          |17.869640077853013|1.0             |179.2           |3.25759670495353  |0.1            |187.9          |\n",
      "|7          |18.24668769844995 |1.0             |179.97          |3.3490714967124298|0.1            |150.5          |\n",
      "|8          |19.46502548756101 |1.0             |179.98          |3.547602239681255 |0.1            |199.3          |\n",
      "|9          |19.797204038748713|1.0             |179.47          |3.4675231051944806|0.1            |165.91         |\n",
      "|10         |19.53631883686647 |1.0             |179.97          |3.5193207613823523|0.1            |174.64         |\n",
      "|11         |18.177375670667715|1.0             |179.92          |3.231923192923368 |0.1            |195.0          |\n",
      "|12         |16.343333238292097|1.0             |179.97          |3.0387956418008093|0.1            |167.16         |\n",
      "|13         |15.669757541504573|1.0             |179.58          |3.2096615639963852|0.1            |165.33         |\n",
      "|14         |15.33697080675494 |1.0             |179.38          |3.456425704510823 |0.1            |124.65         |\n",
      "|15         |15.200118344347072|1.0             |179.73          |3.5018175826681706|0.1            |138.4          |\n",
      "|16         |15.627893142963584|1.0             |179.23          |3.699879583678524 |0.1            |143.05         |\n",
      "|17         |15.665891128337863|1.0             |178.63          |4.038762934094026 |0.1            |141.72         |\n",
      "|18         |14.925048359731552|1.0             |179.53          |4.090192997654956 |0.1            |167.05         |\n",
      "|19         |13.878877046415102|1.0             |179.55          |3.7569073178625407|0.1            |133.3          |\n",
      "+-----------+------------------+----------------+----------------+------------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "=== Duration and Distance Statistics (by_zone) ===\n",
      "+----------------------------+------------------+------------------+----------+\n",
      "|pickup_zone_name            |avg_duration_min  |avg_distance_km   |trip_count|\n",
      "+----------------------------+------------------+------------------+----------+\n",
      "|Upper East Side South       |12.135380811492238|1.8119687012812535|1600385   |\n",
      "|Midtown Center              |15.34281556322442 |2.3472229249086816|1583605   |\n",
      "|JFK Airport                 |44.57911016911201 |15.898396643806521|1451287   |\n",
      "|Upper East Side North       |12.396800868206249|2.020183227755782 |1401971   |\n",
      "|Penn Station/Madison Sq West|16.23623370670174 |2.338590846855896 |1162748   |\n",
      "|Midtown East                |14.602667286286056|2.3146664163684525|1142637   |\n",
      "|Times Sq/Theatre District   |16.683768803406608|3.039162697453548 |1125328   |\n",
      "|Lincoln Square East         |12.931742148335397|2.2246940645583484|1026916   |\n",
      "|LaGuardia Airport           |30.83427406147481 |9.687056215203718 |981247    |\n",
      "|Murray Hill                 |14.313360283420861|2.321779171383104 |966478    |\n",
      "|Union Sq                    |13.829461180129028|2.1355994857924836|965369    |\n",
      "|East Chelsea                |16.328232140494027|2.577699865406158 |929463    |\n",
      "|Midtown North               |15.017699955334102|2.4372071417936714|926882    |\n",
      "|Upper West Side South       |12.744929089309814|2.2857635207557245|894717    |\n",
      "|East Village                |13.639543263419347|2.522862286370317 |889331    |\n",
      "|Clinton East                |13.921763708463406|2.588057939128114 |846302    |\n",
      "|West Village                |13.880573880410312|2.2945005504128115|799400    |\n",
      "|Lenox Hill West             |12.314953838480621|2.0634947958366707|761890    |\n",
      "|Midtown South               |14.45141312920984 |2.4376541048170397|760716    |\n",
      "|Gramercy                    |13.434997819418369|2.270404350555016 |678718    |\n",
      "+----------------------------+------------------+------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Analyze trip duration and distance\n",
    "duration_distance_stats = analyze_trip_duration_distance(df_enriched)\n",
    "\n",
    "for stat_type, stats_df in duration_distance_stats:\n",
    "    print(f\"\\n=== Duration and Distance Statistics ({stat_type}) ===\")\n",
    "    stats_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Revenue and Payment Type Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:29:55,221 - src.analysis - INFO - Analyzing revenue by payment type\n",
      "2025-11-27 09:30:30,220 - src.analysis - INFO - Payment type distribution in data:\n",
      "2025-11-27 09:30:30,222 - src.analysis - INFO -   Payment Type 1: 25,078,323 trips\n",
      "2025-11-27 09:30:30,222 - src.analysis - INFO -   Payment Type 0: 6,983,089 trips\n",
      "2025-11-27 09:30:30,223 - src.analysis - INFO -   Payment Type 2: 3,380,359 trips\n",
      "2025-11-27 09:30:30,224 - src.analysis - INFO -   Payment Type 3: 63,272 trips\n",
      "2025-11-27 09:30:30,225 - src.analysis - INFO -   Payment Type 4: 44,218 trips\n",
      "2025-11-27 09:30:30,225 - src.analysis - INFO -   Payment Type 5: 1 trips\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Revenue Analysis by Payment Type ===\n",
      "+------------+---------------------+-----------+--------------------+--------------------+\n",
      "|payment_type|payment_type_name    |total_trips|total_revenue       |avg_revenue_per_trip|\n",
      "+------------+---------------------+-----------+--------------------+--------------------+\n",
      "|1           |Credit Card          |25078322   |4.877456704800306E8 |19.44889576264435   |\n",
      "|0           |Unknown/Not Specified|6983079    |1.4482577584000388E8|20.739529917963676  |\n",
      "|2           |Cash                 |3380372    |6.456816693000035E7 |19.100905737593482  |\n",
      "|3           |No Charge            |63272      |1123283.9300000002  |17.753254678214695  |\n",
      "|4           |Dispute              |44217      |917682.91           |20.75407445100301   |\n",
      "|5           |Unknown              |1          |51.8                |51.8                |\n",
      "+------------+---------------------+-----------+--------------------+--------------------+\n",
      "\n",
      "\n",
      "Total Revenue: $699,181,256.41\n"
     ]
    }
   ],
   "source": [
    "# Analyze revenue by payment type\n",
    "revenue_analysis = analyze_revenue_payment(df_enriched)\n",
    "\n",
    "if revenue_analysis:\n",
    "    print(\"=== Revenue Analysis by Payment Type ===\")\n",
    "    revenue_analysis.show(truncate=False)\n",
    "    \n",
    "    # Calculate total revenue\n",
    "    from pyspark.sql.functions import sum as spark_sum\n",
    "    total_revenue = revenue_analysis.agg(spark_sum(\"total_revenue\").alias(\"total_revenue\")).collect()[0][\"total_revenue\"]\n",
    "    print(f\"\\nTotal Revenue: ${total_revenue:,.2f}\")\n",
    "else:\n",
    "    print(\"Revenue analysis not available (missing payment_type column)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Storage - MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:31:42,238 - src.mongodb_operations - INFO - Saving all analysis results to MongoDB\n",
      "2025-11-27 09:31:42,240 - src.mongodb_operations - INFO - Saving DataFrame to MongoDB: taxi_analysis.trips_by_hour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving analysis results to MongoDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:32:13,637 - src.mongodb_operations - INFO - Successfully connected to MongoDB\n",
      "2025-11-27 09:32:13,702 - src.mongodb_operations - INFO - Cleared existing data in trips_by_hour\n",
      "2025-11-27 09:32:13,775 - src.mongodb_operations - INFO - Inserted 24 records into trips_by_hour\n",
      "2025-11-27 09:32:13,832 - src.mongodb_operations - INFO - Saving DataFrame to MongoDB: taxi_analysis.trips_by_day\n",
      "2025-11-27 09:32:45,231 - src.mongodb_operations - INFO - Successfully connected to MongoDB\n",
      "2025-11-27 09:32:45,289 - src.mongodb_operations - INFO - Cleared existing data in trips_by_day\n",
      "2025-11-27 09:32:45,352 - src.mongodb_operations - INFO - Inserted 7 records into trips_by_day\n",
      "2025-11-27 09:32:45,408 - src.mongodb_operations - INFO - Saving DataFrame to MongoDB: taxi_analysis.zones_activity\n",
      "2025-11-27 09:33:28,698 - src.mongodb_operations - INFO - Successfully connected to MongoDB\n",
      "2025-11-27 09:33:28,759 - src.mongodb_operations - INFO - Cleared existing data in zones_activity\n",
      "2025-11-27 09:33:28,818 - src.mongodb_operations - INFO - Inserted 20 records into zones_activity\n",
      "2025-11-27 09:33:28,874 - src.mongodb_operations - INFO - Saving DataFrame to MongoDB: taxi_analysis.revenue_analysis\n",
      "2025-11-27 09:34:02,763 - src.mongodb_operations - INFO - Successfully connected to MongoDB\n",
      "2025-11-27 09:34:02,821 - src.mongodb_operations - INFO - Cleared existing data in revenue_analysis\n",
      "2025-11-27 09:34:02,892 - src.mongodb_operations - INFO - Inserted 6 records into revenue_analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved all results to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# Prepare all analysis results for MongoDB\n",
    "analysis_results = {\n",
    "    \"trips_by_hour\": hourly_demand,\n",
    "    \"trips_by_day\": daily_demand,\n",
    "    \"zones_activity\": zone_results.get(\"combined_zone_activity\"),\n",
    "    \"revenue_analysis\": revenue_analysis\n",
    "}\n",
    "\n",
    "# Save to MongoDB (only if URI is configured)\n",
    "if MONGODB_URI and MONGODB_URI != \"mongodb+srv://username:password@cluster.mongodb.net/\":\n",
    "    try:\n",
    "        print(\"Saving analysis results to MongoDB...\")\n",
    "        save_analysis_results(\n",
    "            analysis_results,\n",
    "            MONGODB_URI,\n",
    "            MONGODB_DATABASE,\n",
    "            MONGODB_COLLECTIONS\n",
    "        )\n",
    "        print(\"\\nSuccessfully saved all results to MongoDB!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving to MongoDB: {e}\")\n",
    "        print(\"Please check your MongoDB connection string and network access.\")\n",
    "else:\n",
    "    print(\"MongoDB URI not configured. Skipping MongoDB storage.\")\n",
    "    print(\"Please update MONGODB_URI in the configuration cell to save to MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Data for Power BI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:34:02,969 - src.mongodb_operations - INFO - Exporting DataFrame to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\hourly_demand.csv in csv format\n",
      "2025-11-27 09:34:03,032 - src.mongodb_operations - INFO - Successfully exported to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\hourly_demand.csv\n",
      "2025-11-27 09:34:03,033 - src.mongodb_operations - INFO - Exporting DataFrame to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\daily_demand.csv in csv format\n",
      "2025-11-27 09:34:03,067 - src.mongodb_operations - INFO - Successfully exported to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\daily_demand.csv\n",
      "2025-11-27 09:34:03,068 - src.mongodb_operations - INFO - Exporting DataFrame to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\zone_activity.csv in csv format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting data for Power BI...\n",
      "✓ Exported hourly_demand.csv\n",
      "✓ Exported daily_demand.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:34:05,222 - src.mongodb_operations - INFO - Successfully exported to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\zone_activity.csv\n",
      "2025-11-27 09:34:05,224 - src.mongodb_operations - INFO - Exporting DataFrame to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\revenue_analysis.csv in csv format\n",
      "2025-11-27 09:34:05,278 - src.mongodb_operations - INFO - Successfully exported to C:\\Users\\alanv\\Documents\\Projects\\Big data\\proyecto_final\\output\\revenue_analysis.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exported zone_activity.csv\n",
      "✓ Exported revenue_analysis.csv\n",
      "\n",
      "All exports complete! Files are ready for Power BI import.\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Export all analysis results to CSV for Power BI\n",
    "print(\"Exporting data for Power BI...\")\n",
    "\n",
    "if hourly_demand:\n",
    "    export_for_powerbi(hourly_demand, str(OUTPUT_DIR / \"hourly_demand.csv\"))\n",
    "    print(\"✓ Exported hourly_demand.csv\")\n",
    "\n",
    "if daily_demand:\n",
    "    export_for_powerbi(daily_demand, str(OUTPUT_DIR / \"daily_demand.csv\"))\n",
    "    print(\"✓ Exported daily_demand.csv\")\n",
    "\n",
    "if zone_results.get(\"combined_zone_activity\"):\n",
    "    export_for_powerbi(\n",
    "        zone_results[\"combined_zone_activity\"],\n",
    "        str(OUTPUT_DIR / \"zone_activity.csv\")\n",
    "    )\n",
    "    print(\"✓ Exported zone_activity.csv\")\n",
    "\n",
    "if revenue_analysis:\n",
    "    export_for_powerbi(revenue_analysis, str(OUTPUT_DIR / \"revenue_analysis.csv\"))\n",
    "    print(\"✓ Exported revenue_analysis.csv\")\n",
    "\n",
    "print(\"\\nAll exports complete! Files are ready for Power BI import.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROJECT SUMMARY ===\n",
      "\n",
      "Total trips analyzed: 35,549,388\n",
      "Peak hour: 12:00 (2,384,934 trips)\n",
      "Busiest day: Friday (5,764,059 trips)\n",
      "Most active zone: Upper East Side South (3,044,718 trips)\n",
      "Total revenue: $699,181,152.82\n",
      "\n",
      "=== Analysis Complete ===\n",
      "\n",
      "Next steps:\n",
      "1. Review exported CSV files in the output/ directory\n",
      "2. Import data into Power BI for visualization\n",
      "3. Connect to MongoDB collections for real-time dashboards\n",
      "4. Review project documentation in docs/ folder\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics\n",
    "print(\"=== PROJECT SUMMARY ===\\n\")\n",
    "\n",
    "print(f\"Total trips analyzed: {df_enriched.count():,}\")\n",
    "\n",
    "if hourly_demand:\n",
    "    from pyspark.sql.functions import desc\n",
    "    peak = hourly_demand.orderBy(desc(\"total_trips\")).first()\n",
    "    print(f\"Peak hour: {peak['hour_of_day']}:00 ({peak['total_trips']:,} trips)\")\n",
    "\n",
    "if daily_demand:\n",
    "    busiest_day = daily_demand.orderBy(desc(\"total_trips\")).first()\n",
    "    print(f\"Busiest day: {busiest_day['day_name']} ({busiest_day['total_trips']:,} trips)\")\n",
    "\n",
    "if zone_results.get(\"combined_zone_activity\"):\n",
    "    top_zone = zone_results[\"combined_zone_activity\"].first()\n",
    "    print(f\"Most active zone: {top_zone['zone_name']} ({top_zone['total_activity']:,} trips)\")\n",
    "\n",
    "if revenue_analysis:\n",
    "    from pyspark.sql.functions import sum as spark_sum\n",
    "    total_rev = revenue_analysis.agg(spark_sum(\"total_revenue\").alias(\"total\")).collect()[0][\"total\"]\n",
    "    print(f\"Total revenue: ${total_rev:,.2f}\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review exported CSV files in the output/ directory\")\n",
    "print(\"2. Import data into Power BI for visualization\")\n",
    "print(\"3. Connect to MongoDB collections for real-time dashboards\")\n",
    "print(\"4. Review project documentation in docs/ folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"Spark session stopped.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
